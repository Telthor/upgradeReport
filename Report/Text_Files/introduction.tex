% !TEX root = ../Thesis.tex

\chapter{Introduction}
% \begin{center}
% \begin{minipage}{0.5\textwidth}
% \begin{small}
% \emph{At midnight all the agents and superhuman crew come out and round up everyone who knows more than they do}
% \end{small}
% \end{minipage}
% \vspace{0.5cm}
% \end{center}
\epigraph{\textit{At midnight all the agents and superhuman crew come out and round up everyone that knows more than they do}}{}
Quantum computing has been an active field of research since the concept was first suggested by Richard Feynman in the early 1980s \cite{Feynman1982}.
Originally proposed as an efficient method for simulating chemical processes (something that traditional computers find extremely taxing) the discovery of several algorithms offering significant speed increases over classical computers has further fueLled research \cite{Shor1994,Shor1997}.
Strong initial scepticism abounded regarding the potential for quantum computers to exist in the real world, primarily due to the concerns that error correction with such a complex device would be impossible\cite{Preskill1997}.
This pessimism gave way with the identification of an error threshold for quantum computation.
Given an error rate below a critical threshold it was possible to perform an arbitrarily long computation with negligible possibility of significant error \cite{Shor1996,Aharonov1997}.
Following these discoveries serious attention has been given to the development of error correcting codes that might be implemented to allow a physical quantum computer to be \emph{fault tolerant}.
\\
Gottesman identified the class of error correcting codes known as \emph{stabilizer codes}, where codes are defined by the group of logical operators that leave the code unchanged \cite{Gottesman1997a}.
This class of quantum error correcting codes have become the dominant form in theoretical research.
Of these one in particular has become the focus of much of the ongoing research of quantum computing, \emph{the surface code}, developed by Bravyi and Kitaev \cite{Bravyi1998}.
Although other quantum error correcting codes (such as colour codes \cite{Vasmer2018}) exist, the surface code has become the focus for experimental implementations. This is due mainly to the relatively high error threshold that it is able to tolerate, $\sim0.5\%$, and the simple architecture of a planar grid of qubits.
\\
In recent years there has been rapid progress in the development of physical qubits.
Groups in both the academic and private sectors have shown small numbers of qubits functioning with error rates above the fault tolerant threshold \cite{Barends2015,Reagor2017}.
The successful recent approaches have tended to focus on superconducting circuits to produce their qubits.
Whilst these have proved excellent for the small numbers of qubits currently in use, it is likely that they will present significant additional challenges when scaling to numbers sufficient for useful, fault-tolerant quantum computation.
With the numbers required likely to be close to $100 \times 10^6$ and the current size of these qubits close to 1mm$^2$, it will likely be impossible to use these qubits in their current form in a fault-tolerant quantum computer.
\\
Although there are many alternative systems that could provide a qubit, this paper will focus on the use of the spins of nuclei and electrons bound to donors in semiconductors, particularly silicon.
A seminal paper by Kane \cite{Kane1998} stimulated much of the research interest in this field.
He proposed using the spin of phosphorus nuclei in silicon as qubits with the ability to mediate interactions between neighbouring donor nuclei using the interaction between the electrons bound to each.
These types of qubit are attractive due to their exceptionally long coherence times, the time that the qubit reliably stores quantum information for. 
A long coherence time relative to qubit gate times is essential, as this determines the error rate of the qubits.
Coherence times as long as several seconds have been reported for donor spin qubits in silicon, whilst gate times can be as low as several nanoseconds \cite{Wolfowicz2013}. 
Despite these advantages, development of these types of qubits for quantum computers has lagged behind the superconducting and ion trap versions \cite{Ballance2015}. 
This is due to the difficulty of isolating and addressing single donors in a silicon lattice. 
Kane's proposal required sub nano-metre precision in qubit placement to facilitate inter-qubit interactions. 
Even if this precision were achieved there remains the issue of how the requisite control circuitry could be integrated into such a dense design.
This has lead to the development of more modern proposals to both overcome these difficulties and also to implement surface code based error correction.
\\
\\
One such proposal is from O'Gormann et al \cite{OGorman2014}. 
This proposal takes a similar approach to Kane, with qubits being donor spins in a silicon lattice. 
Where it differs significantly is in its use of two lattices of qubits. 
One of these is for the storage of data, whilst the other performs measurements on these data qubits. 
This measurement stage is placed above the data stage and held close, within 40nm, and moved in a repeating cycle over the data qubits.
This allows each measurement qubit to perform $\hat{X}$ or $\hat{Z}$ measurement on groups of four data qubits, the stabilizer measurements that make up the fundamental units of surface code.
This architecture allows for data qubits to be placed much farther apart - since no direct interaction between them is required.
Several key research questions remain:
\begin{enumerate}
	\item{What donor species should be used for both types of qubit?}
	\item{How are the measurement qubits to be read out?}
	\item{How are the qubits to be controlled?}
\end{enumerate}
Whilst donors in silicon make excellent choices for the data qubits due to the properties stated above, a different qubit species is required for the measurement qubits to avoid an unwanted exchange interaction between the two lattices.
Optical qubit readout is suggested in the proposal by O'Gormann et al and is a well studied means of reading the state of spin qubits, particularly in nitrogen-vacancy (NV) centres in diamond \cite{Liu2017}.
A concern with optical readout is the impact that illumination can have on the coherence times of donors in silicon. 
Silicon has a band gap energy equivalent to approximately 1058nm or photon energy of 1.17eV. 
Illumination at shorter wavelengths than this will create free electrons in the silicon conduction band.
These can scatter off the electrons bound to donors, causing them to relax and shortening the $T_1$ time of the qubits as a whole \cite{Ross2017}.  
NV centres are read out at between 500nm and 600nm, illumination that would reduce data qubit coherence times and increase the qubit error rate. 
Alternative optically addressed spin qubits at higher wavelengths exist, such as the di-vacancy centre in silicon carbide \cite{Christle2014}, but a vital question is what wavelengths can be used for read-out without compromising data qubit coherence times.
This report addresses this question by examining the effect of various laser wavelengths close to the silicon band gap on the coherence times of electrons bound to phosphorus donors in silicon.
\\
Another key question presented by the O'Gormann proposal is how to control the data qubits.
The frequencies traditionally used for electron spin resonance are between 8GHz and 10GHz. 
Electromagnetic radiation at these frequencies require large coaxial cables and cavities for transmission. 
This makes it almost impossible to individually address qubits using microwaves. 
Instead the solution proposed by Kane is to use global microwave pulses, addressing all qubits at once.
To selectively control qubits the DC Stark shift can be employed - DC electric fields can be used to shift the electron spin transition frequency meaning that a global microwave field will not effect them. 
Unlike RF radiation, DC signals are easily multiplexed and the commercial electronics industry has achieved fabrication precision well within that required by the O'Gormann proposal.
In addition to the potential control benefits provided by the Stark shift, it can bring problems. 
Inhomogeneous electric fields near spin qubits would alter the energy of their transition, potentially leading to decoherence.
It is also beneficial, therefore, to identify systems that only experience a small Stark shift, as this would render them much more resistant to electric field noise and make them potentially ideal data qubits.
One such system is explored in this report, the unpaired electron bound to a selenium$+$ donor in silicon.
Among these is the hyperfine interaction between the donor electron and the silicon-29 nuclei present in natural silicon.
The nuclear bath has been identified as a potential quantum register and the ability to tune the interaction between data qubits and memory could be of use. 





